{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature preprocessing and selection apply to all features. Therefore, the pipleine for that part is same for all outcomes\n",
    "#different model strategies apply to different outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data and drop unrelated variables \n",
    "df = pd.read_csv('C:\\\\Users\\\\azhang\\\\Documents\\\\county health rank 2018\\\\cleaned.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "df=df.drop(columns=['5-Digit FIPS Code'])\n",
    "df=df.drop(columns=['state_county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.percent_non_hispanic_black=df.percent_non_hispanic_black*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_american_indian=df.percent_american_indian*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_asian=df.percent_asian*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_pacific_islander=df.percent_pacific_islander*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_hispanic=df.percent_hispanic*df.percent_non_hispanic_white\n",
    "\n",
    "df=df.drop(columns='percent_non_hispanic_white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test out feature selection by p value and correlations on whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate outcomes and feature\n",
    "out = df.iloc[:,9]\n",
    "#only focus on one outcome\n",
    "\n",
    "#out.columns\n",
    "feature=df.iloc[:,12:70]\n",
    "#feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azhang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#build model on non missing Ys\n",
    "notnans = pd.DataFrame(out.notnull()).all(axis=1)\n",
    "Y_notnans = out[notnans]\n",
    "X_notnans = feature[notnans]\n",
    "#Y_notnans.describe()\n",
    "\n",
    "# Split into 75% train and 25% test\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_notnans, Y_notnans,\n",
    "                                                    train_size=0.75,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale y train\n",
    "Y_train1=pd.DataFrame(Y_train)\n",
    "yscale=preprocessing.StandardScaler()\n",
    "Y_train2=yscale.fit_transform(Y_train1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before pipeline building, test different things out\n",
    "#imputation\n",
    "imputer=preprocessing.Imputer(missing_values=numpy.nan, strategy='mean', axis=0, verbose=0, copy=True)\n",
    "X_train1=pd.DataFrame(imputer.fit_transform(X_train))\n",
    "X_train1.columns=X_train.columns\n",
    "\n",
    "#scaling using mean and standard deviation \n",
    "scaler = preprocessing.RobustScaler()\n",
    "X_train2 = pd.DataFrame(scaler.fit_transform(X_train1))\n",
    "X_train2.columns=X_train1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get f and p values for each feature\n",
    "#from sklearn.feature_selection import f_regression\n",
    "f_values, p_values = f_regression(X_train2, Y_train2)\n",
    "\n",
    "p1=pd.concat([pd.DataFrame(X_train2.columns),pd.DataFrame(p_values.round(3))], axis=1)\n",
    "p1.columns=['feature','p_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>other_primary_care_providers</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nonwhite_white_residential_segregation</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>percent_age_below_18</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>percent_english_nonproficent</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   feature  p_val\n",
       "18            other_primary_care_providers  0.326\n",
       "32  nonwhite_white_residential_segregation  0.982\n",
       "48                    percent_age_below_18  0.282\n",
       "55            percent_english_nonproficent  0.661"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get p values that are larger than 0.05 as potential candidates to exclude \n",
    "p1[p1['p_val']>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>food_enviroment_index</td>\n",
       "      <td>food_insecurity</td>\n",
       "      <td>0.761431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>uninsured</td>\n",
       "      <td>uninsured_children</td>\n",
       "      <td>0.787581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>median_household_income</td>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>0.800532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>children_eligible_for_free_lunch</td>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>0.812453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>uninsured_adults</td>\n",
       "      <td>uninsured</td>\n",
       "      <td>0.988792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>food_insecurity</td>\n",
       "      <td>food_insecurity</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature0             feature1  correlation\n",
       "1648             food_enviroment_index      food_insecurity     0.761431\n",
       "1649                         uninsured   uninsured_children     0.787581\n",
       "1650           median_household_income  children_in_poverty     0.800532\n",
       "1651  children_eligible_for_free_lunch  children_in_poverty     0.812453\n",
       "1652                  uninsured_adults            uninsured     0.988792\n",
       "1653                   food_insecurity      food_insecurity     1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get correlation between features \n",
    "#cov = numpy.cov(X_train2, rowvar=False)\n",
    "#pd.DataFrame(cov)\n",
    "\n",
    "corr=pd.DataFrame(X_train2.corr().abs().unstack().sort_values().drop_duplicates())\n",
    "\n",
    "corr.reset_index(inplace=True) \n",
    "corr.columns=[ 'feature0','feature1','correlation']\n",
    "corr[corr['correlation']>=0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because uninsured and children in poverty are highly associated with other variables from observation from train and test dataset, in validation, it will be dropped as well\n",
    "#outcome in train/test: Y_train2\n",
    "#feature in train/test: X_train_f\n",
    "X_train_f=X_train.drop(columns=['uninsured'])\n",
    "X_train_f=X_train_f.drop(columns=['children_in_poverty'])\n",
    "X_train_f=X_train_f.drop(columns=['food_enviroment_index'])\n",
    "\n",
    "#outcome in val: Y_val2\n",
    "Y_val1=pd.DataFrame(Y_val)\n",
    "yscale=preprocessing.StandardScaler()\n",
    "Y_val2=yscale.fit_transform(Y_val1).ravel()\n",
    "\n",
    "#feature in val: X_val_f\n",
    "X_val_f=X_val.drop(columns=['uninsured'])\n",
    "X_val_f=X_val_f.drop(columns=['children_in_poverty'])\n",
    "X_val_f=X_val_f.drop(columns=['food_enviroment_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8695177302670121\n",
      "-0.1291350698400012\n"
     ]
    }
   ],
   "source": [
    "#make pipeline with mean imputation and standard scaler, lassoCV feature selection, and linear regression as prediction model\n",
    "\n",
    "#note:feature importance selection did not use recursive methods because it's not performing that well, and it takes too long\n",
    "\n",
    "pipe_lr=pipeline.make_pipeline(preprocessing.Imputer(missing_values=numpy.nan, strategy='mean', axis=0),\n",
    "              preprocessing.StandardScaler(), \n",
    "              #feature_selection.SelectFromModel(linear_model.LassoCV()),\n",
    "              #feature_selection.RFECV(linear_model.LassoCV(), cv=10),\n",
    "              linear_model.LinearRegression())\n",
    "print(model_selection.cross_val_score(pipe_lr,  X_train_f, Y_train2, cv=10, scoring='r2').mean())\n",
    "print(model_selection.cross_val_score(pipe_lr,  X_train_f, Y_train2, cv=10, scoring=\"neg_mean_squared_error\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values=nan, strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit pipeline so that train set evaluation and coefficient extraction can be applied, and val set evaluation can also be applied \n",
    "pipe_lr.fit(X_train_f,Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=pd.DataFrame(pipe_lr.steps[2][1].coef_)\n",
    "coef.columns=pd.DataFrame(out).columns\n",
    "coef.index=X_train_f.columns\n",
    "coef.to_csv('coef9C', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on test r2\n",
    "r2=metrics.r2_score(Y_val2, pipe_lr.predict(X_val_f))\n",
    "#evaluate on test mean squared error\n",
    "mse=metrics.mean_squared_error(Y_val2, pipe_lr.predict(X_val_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3135"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample size\n",
    "Y_notnans.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>poor_physical_health_days</th>\n",
       "      <td>0.856842</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>3135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 r2       mse  sample_size\n",
       "poor_physical_health_days  0.856842  0.143158       3135.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl=[r2,mse,Y_notnans.shape[0]]\n",
    "evl1=pd.DataFrame(evl).T\n",
    "evl1.columns=['r2','mse','sample_size']\n",
    "evl1.index=pd.DataFrame(out).columns\n",
    "evl1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evl1.to_csv('evl9C', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
