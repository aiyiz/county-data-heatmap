{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature preprocessing and selection apply to all features. Therefore, the pipleine for that part is same for all outcomes\n",
    "#different model strategies apply to different outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data and drop unrelated variables \n",
    "df = pd.read_csv('C:\\\\Users\\\\azhang\\\\Documents\\\\county health rank 2018\\\\cleaned.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "df=df.drop(columns=['5-Digit FIPS Code'])\n",
    "df=df.drop(columns=['state_county'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.percent_non_hispanic_black=df.percent_non_hispanic_black*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_american_indian=df.percent_american_indian*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_asian=df.percent_asian*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_pacific_islander=df.percent_pacific_islander*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_hispanic=df.percent_hispanic*df.percent_non_hispanic_white\n",
    "\n",
    "df=df.drop(columns='percent_non_hispanic_white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test out feature selection by p value and correlations on whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate outcomes and feature\n",
    "out = df.iloc[:,1]\n",
    "#only focus on one outcome\n",
    "\n",
    "#out.columns\n",
    "feature=df.iloc[:,13:70]\n",
    "#feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azhang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#build model on non missing Ys\n",
    "notnans = pd.DataFrame(out.notnull()).all(axis=1)\n",
    "Y_notnans = out[notnans]\n",
    "X_notnans = feature[notnans]\n",
    "#Y_notnans.describe()\n",
    "\n",
    "# Split into 75% train and 25% test\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_notnans, Y_notnans,\n",
    "                                                    train_size=0.75,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 316, 1789, 2324, 1217, 2643, 3021, 1278,  213, 2252, 3025,\n",
       "            ...\n",
       "            1679, 2833, 1149, 1108, 3110, 1412, 1104, 2704, 2701,  207],\n",
       "           dtype='int64', length=315)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale y train\n",
    "Y_train1=pd.DataFrame(Y_train)\n",
    "yscale=preprocessing.StandardScaler()\n",
    "Y_train2=yscale.fit_transform(Y_train1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before pipeline building, test different things out\n",
    "#imputation\n",
    "imputer=preprocessing.Imputer(missing_values=numpy.nan, strategy='mean', axis=0, verbose=0, copy=True)\n",
    "X_train1=pd.DataFrame(imputer.fit_transform(X_train))\n",
    "X_train1.columns=X_train.columns\n",
    "\n",
    "#scaling using mean and standard deviation \n",
    "scaler = preprocessing.RobustScaler()\n",
    "X_train2 = pd.DataFrame(scaler.fit_transform(X_train1))\n",
    "X_train2.columns=X_train1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get f and p values for each feature\n",
    "#from sklearn.feature_selection import f_regression\n",
    "f_values, p_values = f_regression(X_train2, Y_train2)\n",
    "\n",
    "p1=pd.concat([pd.DataFrame(X_train2.columns),pd.DataFrame(p_values.round(3))], axis=1)\n",
    "p1.columns=['feature','p_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drug_overdose_deaths_modeled</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>uninsured_children</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>severe_housing_problems</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>percent_age_below_18</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         feature  p_val\n",
       "3   drug_overdose_deaths_modeled  0.055\n",
       "15            uninsured_children  0.265\n",
       "43       severe_housing_problems  0.367\n",
       "47          percent_age_below_18  0.688"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get p values that are larger than 0.05 as potential candidates to exclude \n",
    "p1[p1['p_val']>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>teen_births</td>\n",
       "      <td>0.751559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>some_college</td>\n",
       "      <td>disconnected_youth</td>\n",
       "      <td>0.751846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>children_eligible_for_free_lunch</td>\n",
       "      <td>children_in_single_parent_households</td>\n",
       "      <td>0.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>uninsured_children</td>\n",
       "      <td>uninsured</td>\n",
       "      <td>0.766663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>children_in_single_parent_households</td>\n",
       "      <td>0.804027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>median_household_income</td>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>0.824042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>children_eligible_for_free_lunch</td>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>0.864450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>uninsured_adults</td>\n",
       "      <td>uninsured</td>\n",
       "      <td>0.992475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>limited_access_to_healthy_foods</td>\n",
       "      <td>limited_access_to_healthy_foods</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature0                              feature1  \\\n",
       "1588               children_in_poverty                           teen_births   \n",
       "1589                      some_college                    disconnected_youth   \n",
       "1590  children_eligible_for_free_lunch  children_in_single_parent_households   \n",
       "1591                uninsured_children                             uninsured   \n",
       "1592               children_in_poverty  children_in_single_parent_households   \n",
       "1593           median_household_income                   children_in_poverty   \n",
       "1594  children_eligible_for_free_lunch                   children_in_poverty   \n",
       "1595                  uninsured_adults                             uninsured   \n",
       "1596   limited_access_to_healthy_foods       limited_access_to_healthy_foods   \n",
       "\n",
       "      correlation  \n",
       "1588     0.751559  \n",
       "1589     0.751846  \n",
       "1590     0.753425  \n",
       "1591     0.766663  \n",
       "1592     0.804027  \n",
       "1593     0.824042  \n",
       "1594     0.864450  \n",
       "1595     0.992475  \n",
       "1596     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get correlation between features \n",
    "#cov = numpy.cov(X_train2, rowvar=False)\n",
    "#pd.DataFrame(cov)\n",
    "\n",
    "corr=pd.DataFrame(X_train2.corr().abs().unstack().sort_values().drop_duplicates())\n",
    "\n",
    "corr.reset_index(inplace=True) \n",
    "corr.columns=[ 'feature0','feature1','correlation']\n",
    "corr[corr['correlation']>=0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because uninsured and children in poverty are highly associated with other variables from observation from train and test dataset, in validation, it will be dropped as well\n",
    "#outcome in train/test: Y_train2\n",
    "#feature in train/test: X_train_f\n",
    "X_train_f=X_train.drop(columns=['uninsured'])\n",
    "X_train_f=X_train_f.drop(columns=['children_in_poverty'])\n",
    "X_train_f=X_train_f.drop(columns=['food_enviroment_index'])\n",
    "\n",
    "#outcome in val: Y_val2\n",
    "Y_val1=pd.DataFrame(Y_val)\n",
    "yscale=preprocessing.StandardScaler()\n",
    "Y_val2=yscale.fit_transform(Y_val1).ravel()\n",
    "\n",
    "#feature in val: X_val_f\n",
    "X_val_f=X_val.drop(columns=['uninsured'])\n",
    "X_val_f=X_val_f.drop(columns=['children_in_poverty'])\n",
    "X_val_f=X_val_f.drop(columns=['food_enviroment_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4981354668094807\n",
      "-0.5097570055080793\n"
     ]
    }
   ],
   "source": [
    "#make pipeline with mean imputation and standard scaler, lassoCV feature selection, and linear regression as prediction model\n",
    "\n",
    "#note:feature importance selection did not use recursive methods because it's not performing that well, and it takes too long\n",
    "\n",
    "pipe_lr=pipeline.make_pipeline(preprocessing.Imputer(missing_values=numpy.nan, strategy='mean', axis=0),\n",
    "              preprocessing.StandardScaler(), \n",
    "              #feature_selection.SelectFromModel(linear_model.LassoCV()),\n",
    "              #feature_selection.RFECV(linear_model.LassoCV(), cv=10),\n",
    "              linear_model.LinearRegression())\n",
    "print(model_selection.cross_val_score(pipe_lr,  X_train_f, Y_train2, cv=10, scoring='r2').mean())\n",
    "print(model_selection.cross_val_score(pipe_lr,  X_train_f, Y_train2, cv=10, scoring=\"neg_mean_squared_error\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values=nan, strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit pipeline so that train set evaluation and coefficient extraction can be applied, and val set evaluation can also be applied \n",
    "pipe_lr.fit(X_train_f,Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=pd.DataFrame(pipe_lr.steps[2][1].coef_)\n",
    "coef.columns=pd.DataFrame(out).columns\n",
    "coef.index=X_train_f.columns\n",
    "coef.to_csv('coef1C', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on test r2\n",
    "r2=metrics.r2_score(Y_val2, pipe_lr.predict(X_val_f))\n",
    "#evaluate on test mean squared error\n",
    "mse=metrics.mean_squared_error(Y_val2, pipe_lr.predict(X_val_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample size\n",
    "Y_notnans.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evl=[r2,mse,Y_notnans.shape[0]]\n",
    "evl1=pd.DataFrame(evl).T\n",
    "evl1.columns=['r2','mse','sample_size']\n",
    "evl1.index=pd.DataFrame(out).columns\n",
    "evl1\n",
    "evl1.to_csv('evl1C', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>infant_mortality</th>\n",
       "      <td>0.560828</td>\n",
       "      <td>0.439172</td>\n",
       "      <td>1260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        r2       mse  sample_size\n",
       "infant_mortality  0.560828  0.439172       1260.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
