{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature preprocessing and selection apply to all features. Therefore, the pipleine for that part is same for all outcomes\n",
    "#different model strategies apply to different outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data and drop unrelated variables \n",
    "df = pd.read_csv('C:\\\\Users\\\\azhang\\\\Documents\\\\county health rank 2018\\\\cleaned.csv')\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "df=df.drop(columns=['5-Digit FIPS Code'])\n",
    "df=df.drop(columns=['state_county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.percent_non_hispanic_black=df.percent_non_hispanic_black*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_american_indian=df.percent_american_indian*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_asian=df.percent_asian*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_pacific_islander=df.percent_pacific_islander*df.percent_non_hispanic_white\n",
    "\n",
    "df.percent_hispanic=df.percent_hispanic*df.percent_non_hispanic_white\n",
    "\n",
    "df=df.drop(columns='percent_non_hispanic_white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3141, 70)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test out feature selection by p value and correlations on whole data set\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate outcomes and feature\n",
    "out = df.iloc[:,0]\n",
    "#only focus on one outcome\n",
    "\n",
    "#out.columns\n",
    "feature=df.iloc[:,12:70]\n",
    "#feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azhang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#build model on non missing Ys\n",
    "notnans = pd.DataFrame(out.notnull()).all(axis=1)\n",
    "Y_notnans = out[notnans]\n",
    "X_notnans = feature[notnans]\n",
    "#Y_notnans.describe()\n",
    "\n",
    "# Split into 75% train and 25% test\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_notnans, Y_notnans,\n",
    "                                                    train_size=0.75,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale y train\n",
    "Y_train1=pd.DataFrame(Y_train)\n",
    "yscale=preprocessing.StandardScaler()\n",
    "Y_train2=yscale.fit_transform(Y_train1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before pipeline building, test different things out\n",
    "#imputation\n",
    "imputer=preprocessing.Imputer(missing_values=numpy.nan, strategy='mean', axis=0, verbose=0, copy=True)\n",
    "X_train1=pd.DataFrame(imputer.fit_transform(X_train))\n",
    "X_train1.columns=X_train.columns\n",
    "\n",
    "#scaling using mean and standard deviation \n",
    "scaler = preprocessing.RobustScaler()\n",
    "X_train2 = pd.DataFrame(scaler.fit_transform(X_train1))\n",
    "X_train2.columns=X_train1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get f and p values for each feature\n",
    "#from sklearn.feature_selection import f_regression\n",
    "f_values, p_values = f_regression(X_train2, Y_train2)\n",
    "\n",
    "p1=pd.concat([pd.DataFrame(X_train2.columns),pd.DataFrame(p_values.round(3))], axis=1)\n",
    "p1.columns=['feature','p_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>alcohol_impaired_driving_deaths</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>uninsured_children</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>other_primary_care_providers</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nonwhite_white_residential_segregation</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>drinking_water_violations</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>percent_65_and_older</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   feature  p_val\n",
       "12         alcohol_impaired_driving_deaths  0.118\n",
       "16                      uninsured_children  0.198\n",
       "18            other_primary_care_providers  0.074\n",
       "32  nonwhite_white_residential_segregation  0.253\n",
       "43               drinking_water_violations  0.490\n",
       "49                    percent_65_and_older  0.156"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get p values that are larger than 0.05 as potential candidates to exclude \n",
    "p1[p1['p_val']>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>median_household_income</td>\n",
       "      <td>children_eligible_for_free_lunch</td>\n",
       "      <td>0.713382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>limited_access_to_healthy_foods</td>\n",
       "      <td>food_enviroment_index</td>\n",
       "      <td>0.737018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>food_insecurity</td>\n",
       "      <td>0.738777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>uninsured_children</td>\n",
       "      <td>uninsured</td>\n",
       "      <td>0.787408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>food_insecurity</td>\n",
       "      <td>food_enviroment_index</td>\n",
       "      <td>0.800587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>median_household_income</td>\n",
       "      <td>0.808936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>children_eligible_for_free_lunch</td>\n",
       "      <td>children_in_poverty</td>\n",
       "      <td>0.829947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>uninsured_adults</td>\n",
       "      <td>uninsured</td>\n",
       "      <td>0.989299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>food_insecurity</td>\n",
       "      <td>food_insecurity</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature0                          feature1  \\\n",
       "1645           median_household_income  children_eligible_for_free_lunch   \n",
       "1646   limited_access_to_healthy_foods             food_enviroment_index   \n",
       "1647               children_in_poverty                   food_insecurity   \n",
       "1648                uninsured_children                         uninsured   \n",
       "1649                   food_insecurity             food_enviroment_index   \n",
       "1650               children_in_poverty           median_household_income   \n",
       "1651  children_eligible_for_free_lunch               children_in_poverty   \n",
       "1652                  uninsured_adults                         uninsured   \n",
       "1653                   food_insecurity                   food_insecurity   \n",
       "\n",
       "      correlation  \n",
       "1645     0.713382  \n",
       "1646     0.737018  \n",
       "1647     0.738777  \n",
       "1648     0.787408  \n",
       "1649     0.800587  \n",
       "1650     0.808936  \n",
       "1651     0.829947  \n",
       "1652     0.989299  \n",
       "1653     1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get correlation between features \n",
    "#cov = numpy.cov(X_train2, rowvar=False)\n",
    "#pd.DataFrame(cov)\n",
    "\n",
    "corr=pd.DataFrame(X_train2.corr().abs().unstack().sort_values().drop_duplicates())\n",
    "\n",
    "corr.reset_index(inplace=True) \n",
    "corr.columns=[ 'feature0','feature1','correlation']\n",
    "corr[corr['correlation']>=0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because uninsured and children in poverty are highly associated with other variables from observation from train and test dataset, in validation, it will be dropped as well\n",
    "#outcome in train/test: Y_train2\n",
    "#feature in train/test: X_train_f\n",
    "X_train_f=X_train.drop(columns=['uninsured'])\n",
    "X_train_f=X_train_f.drop(columns=['children_in_poverty'])\n",
    "X_train_f=X_train_f.drop(columns=['food_enviroment_index'])\n",
    "\n",
    "#outcome in val: Y_val2\n",
    "Y_val1=pd.DataFrame(Y_val)\n",
    "yscale=preprocessing.StandardScaler()\n",
    "Y_val2=yscale.fit_transform(Y_val1).ravel()\n",
    "\n",
    "#feature in val: X_val_f\n",
    "X_val_f=X_val.drop(columns=['uninsured'])\n",
    "X_val_f=X_val_f.drop(columns=['children_in_poverty'])\n",
    "X_val_f=X_val_f.drop(columns=['food_enviroment_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314994406064435\n",
      "-0.16767676040065216\n"
     ]
    }
   ],
   "source": [
    "#make pipeline with mean imputation and standard scaler, lassoCV feature selection, and linear regression as prediction model\n",
    "\n",
    "#note:feature importance selection did not use recursive methods because it's not performing that well, and it takes too long\n",
    "\n",
    "pipe_lr=pipeline.make_pipeline(preprocessing.Imputer(missing_values=numpy.nan, strategy='mean', axis=0),\n",
    "              preprocessing.StandardScaler(), \n",
    "              #feature_selection.SelectFromModel(linear_model.LassoCV()),\n",
    "              #feature_selection.RFECV(linear_model.LassoCV(), cv=10),\n",
    "              linear_model.LinearRegression())\n",
    "print(model_selection.cross_val_score(pipe_lr,  X_train_f, Y_train2, cv=10, scoring='r2').mean())\n",
    "print(model_selection.cross_val_score(pipe_lr,  X_train_f, Y_train2, cv=10, scoring=\"neg_mean_squared_error\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values=nan, strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit pipeline so that train set evaluation and coefficient extraction can be applied, and val set evaluation can also be applied \n",
    "pipe_lr.fit(X_train_f,Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=pd.DataFrame(pipe_lr.steps[2][1].coef_)\n",
    "coef.columns=pd.DataFrame(out).columns\n",
    "coef.index=X_train_f.columns\n",
    "coef.to_csv('coef0C', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on test r2\n",
    "r2=metrics.r2_score(Y_val2, pipe_lr.predict(X_val_f))\n",
    "#evaluate on test mean squared error\n",
    "mse=metrics.mean_squared_error(Y_val2, pipe_lr.predict(X_val_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3071"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample size\n",
    "Y_notnans.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>premature_age_adjusted_mortality</th>\n",
       "      <td>0.81531</td>\n",
       "      <td>0.18469</td>\n",
       "      <td>3071.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       r2      mse  sample_size\n",
       "premature_age_adjusted_mortality  0.81531  0.18469       3071.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl=[r2,mse,Y_notnans.shape[0]]\n",
    "evl1=pd.DataFrame(evl).T\n",
    "evl1.columns=['r2','mse','sample_size']\n",
    "evl1.index=pd.DataFrame(out).columns\n",
    "evl1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evl1.to_csv('evl0C', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
